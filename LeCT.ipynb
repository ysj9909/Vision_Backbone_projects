{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeCTv2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOooLDpLTaSkzQEAPnpJebV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "m_C-Q9eHr_kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd ./drive/My Drive/vision_transformer/LocallyEnhancedConvTransformer"
      ],
      "metadata": {
        "id": "6jaP8TFksBFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLoavFbild6V"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from functools import partial\n",
        "\n",
        "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
        "\n",
        "\n",
        "# device configuration\n",
        "device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "7yEDxQtoln2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋 준비"
      ],
      "metadata": {
        "id": "BAmLFIWnsLit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = \"CIFAR10\"\n",
        "\n",
        "if dataset == \"STL-10\":\n",
        "\n",
        "    normalize = transforms.Normalize(\n",
        "        mean = [0.5, 0.5, 0.5],\n",
        "        std = [0.5, 0.5, 0.5],\n",
        "     ) \n",
        "    train_transform = transforms.Compose([\n",
        "                                transforms.RandomCrop(96, padding = 4),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.RandAugment(),\n",
        "                                transforms.Resize(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                normalize,\n",
        "    ])\n",
        "    valid_transform = transforms.Compose([\n",
        "                                transforms.Resize(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                normalize,    \n",
        "    ])  \n",
        "    train_dataset = torchvision.datasets.STL10(root = \"./data\", split = 'train', download = True, transform= train_transform)\n",
        "    valid_dataset = torchvision.datasets.STL10(root = \"./data\", split = 'test', download = True, transform = valid_transform)\n",
        "if dataset == \"CIFAR10\":\n",
        "    normalize = transforms.Normalize(\n",
        "        mean = [0.4914, 0.4822, 0.4465],\n",
        "        std = [0.2023, 0.1994, 0.2010],\n",
        "    )\n",
        "    train_transform = transforms.Compose([\n",
        "                                transforms.RandomCrop(32, padding = 4),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.RandAugment(),\n",
        "                                transforms.Resize(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                normalize,\n",
        "    ])\n",
        "    valid_transform = transforms.Compose([\n",
        "                                transforms.Resize(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                normalize,    \n",
        "    ])  \n",
        "    train_dataset = torchvision.datasets.CIFAR10(root = \"./data\", train = True, download = True, transform= train_transform)\n",
        "    valid_dataset = torchvision.datasets.CIFAR10(root = \"./data\", train = False, download = True, transform = valid_transform)\n",
        "\n",
        "if dataset == \"CIFAR100\": \n",
        "    normalize = transforms.Normalize(\n",
        "        mean = [0.5071, 0.4867, 0.4408],\n",
        "        std = [0.2675, 0.2565, 0.2761],\n",
        "    )\n",
        "    train_transform = transforms.Compose([\n",
        "                                transforms.RandomCrop(32, padding = 4),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.RandAugment(),\n",
        "                                transforms.Resize(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                normalize,\n",
        "    ])\n",
        "    valid_transform = transforms.Compose([\n",
        "                                transforms.Resize(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                normalize,    \n",
        "    ])  \n",
        "    train_dataset = torchvision.datasets.CIFAR100(root = \"./data\", train = True, download = True, transform= train_transform)\n",
        "    valid_dataset = torchvision.datasets.CIFAR100(root = \"./data\", train = False, download = True, transform = valid_transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = 64, shuffle = True)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset = valid_dataset, batch_size = 64, shuffle = False)"
      ],
      "metadata": {
        "id": "czqvrZJtsRsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 정의"
      ],
      "metadata": {
        "id": "y-RALyQisSrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvEmbedding(nn.Module):\n",
        "    def __init__(self, \n",
        "                 patch_size = 7, \n",
        "                 stride = 4, \n",
        "                 in_chans = 3, \n",
        "                 embed_dim = 64):\n",
        "        super().__init__()\n",
        "\n",
        "        patch_size = to_2tuple(patch_size)\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        assert max(patch_size) > stride, \"Set larger patch_size than stride\"\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, \n",
        "                              kernel_size = patch_size, \n",
        "                              stride = stride,\n",
        "                              padding = (patch_size[0] // 2, patch_size[1] // 2))\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        x = x.reshape(B, C, -1).transpose(-2, -1)\n",
        "        x = self.norm(x)\n",
        "        return x, H, W"
      ],
      "metadata": {
        "id": "05b53jjNlpT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LocallyEnhancedAttention(nn.Module):\n",
        "    def __init__(self, \n",
        "                 dim,\n",
        "                 num_heads,\n",
        "                 qkv_bias = False,\n",
        "                 attn_drop = 0.,\n",
        "                 proj_drop = 0.,\n",
        "                 kernel_size = 3,\n",
        "                 sr_ratio = 7,):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = dim ** -0.5\n",
        "        self.attention_map = None\n",
        "\n",
        "        self.proj_v = nn.Linear(dim, dim, bias = qkv_bias)\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, kernel_size = kernel_size, stride = 1, \n",
        "                      padding = kernel_size // 2, bias = qkv_bias, groups = dim),\n",
        "            nn.BatchNorm2d(dim),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, kernel_size = kernel_size, stride = 1, \n",
        "                      padding = kernel_size // 2, bias = qkv_bias, groups = dim),\n",
        "            nn.BatchNorm2d(dim),\n",
        "        )\n",
        "        self.downsample_k = nn.AvgPool2d(kernel_size = sr_ratio)\n",
        "        self.downsample_q = nn.AvgPool2d(kernel_size = sr_ratio)\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "\n",
        "        # For upsampling attention map\n",
        "        self.k_upsample = nn.Upsample(scale_factor = sr_ratio, mode = \"bilinear\")\n",
        "        \n",
        "        self.v_upsample = nn.Upsample(scale_factor = sr_ratio, mode = 'bilinear')\n",
        "        self.v_conv = nn.Conv2d(dim, dim, kernel_size = kernel_size, stride = 1,\n",
        "                                padding = kernel_size // 2, groups = dim, bias = False)\n",
        "        self.v_bn = nn.BatchNorm2d(dim)\n",
        "\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        h, w = int(math.sqrt(N)), int(math.sqrt(N))\n",
        "     \n",
        "        v = self.proj_v(x)\n",
        "        skip = v\n",
        "        skip = skip.reshape(B, h, w, C).permute(0, 3, 1, 2)\n",
        "        skip = self.conv1(skip)\n",
        "        q = self.downsample_q(skip)   # B x C x h' x w'\n",
        "        skip = self.gelu(skip)\n",
        "        skip = self.conv2(skip)\n",
        "        k = self.downsample_k(skip)\n",
        "        skip = self.gelu(skip)\n",
        "        skip = skip.reshape(B, C, -1).transpose(-2, -1)\n",
        "\n",
        "        q = q.reshape(B, self.num_heads, C // self.num_heads, -1).transpose(-2, -1)\n",
        "        k = k.reshape(B, self.num_heads, C // self.num_heads, -1).transpose(-2, -1)\n",
        "        v = v.reshape(B, N, self.num_heads, C // self.num_heads).transpose(1, 2)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1))   # B x num_heads x N_ x N_ (N_ = h' * w')\n",
        "\n",
        "        # Upsample attention map\n",
        "        N_ = attn.shape[-1]\n",
        "        h_, w_ = int(math.sqrt(N_)), int(math.sqrt(N_))\n",
        "        attn = attn.reshape(-1, N_, int(math.sqrt(N_)), int(math.sqrt(N_)))\n",
        "        attn = self.k_upsample(attn) * self.scale\n",
        "        attn = attn.reshape(B, self.num_heads, N_, N)\n",
        "\n",
        "        attn = attn.softmax(dim = -1)\n",
        "        self.attention_map = attn\n",
        "        attn = self.attn_drop(attn)\n",
        "        \n",
        "        x = (attn @ v).reshape(B, self.num_heads, h_, w_, -1)\n",
        "        x = x.permute(0, 1, 4, 2, 3).reshape(B, -1, h_, w_)\n",
        "        x = self.v_bn(self.v_conv(self.v_upsample(x)))\n",
        "        x = x.reshape(B, C, -1).transpose(-2, -1) + skip\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "9hymilRtlz9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LocallyEnhancedFeedForward(nn.Module):\n",
        "    def __init__(self, \n",
        "                 in_features,\n",
        "                 hidden_features = None,\n",
        "                 out_features = None,\n",
        "                 act_layer = nn.GELU,\n",
        "                 drop = 0.,\n",
        "                 kernel_size = 3,\n",
        "                 with_bn = True):\n",
        "        super().__init__()\n",
        "\n",
        "        hidden_features = hidden_features or in_features\n",
        "        out_features = out_features or in_features\n",
        "\n",
        "        # Pointwise\n",
        "        self.conv1 = nn.Conv2d(in_features, hidden_features, kernel_size = 1,\n",
        "                               stride = 1, padding = 0)\n",
        "        \n",
        "        # Depthwise\n",
        "        self.conv2 = nn.Conv2d(hidden_features, hidden_features, kernel_size = kernel_size,\n",
        "                               stride = 1, padding = kernel_size // 2, groups = hidden_features)\n",
        "        \n",
        "        # Pointwise\n",
        "        self.conv3 = nn.Conv2d(hidden_features, out_features, kernel_size = 1,\n",
        "                               stride = 1, padding = 0)\n",
        "        \n",
        "        self.act =  act_layer()\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.with_bn = with_bn\n",
        "        if with_bn:\n",
        "            self.bn1 = nn.BatchNorm2d(hidden_features)\n",
        "            self.bn2 = nn.BatchNorm2d(hidden_features)\n",
        "            self.bn3 = nn.BatchNorm2d(out_features)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        x = x.reshape(B, int(math.sqrt(N)), int(math.sqrt(N)), C).permute(0, 3, 1, 2)\n",
        "        if self.with_bn:\n",
        "            x = self.conv1(x)\n",
        "            x = self.bn1(x)\n",
        "            x = self.act(x)\n",
        "            x = self.conv2(x)\n",
        "            x = self.bn2(x)\n",
        "            x = self.act(x)\n",
        "            x = self.drop(x)\n",
        "            x = self.conv3(x)\n",
        "            x = self.bn3(x)\n",
        "        else:\n",
        "            x = self.conv1(x)\n",
        "            x = self.act(x)\n",
        "            x = self.conv2(x)\n",
        "            x = self.act(x)\n",
        "            x = self.drop(x)\n",
        "            x = self.conv3(x)\n",
        "            \n",
        "        x = self.drop(x)\n",
        "        x = x.flatten(2).permute(0, 2, 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "aSULoa2EWg4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, \n",
        "                 dim,\n",
        "                 num_heads,\n",
        "                 mlp_ratio = 4,\n",
        "                 qkv_bias = False,\n",
        "                 drop = 0.,\n",
        "                 attn_drop = 0.,\n",
        "                 drop_path = 0.,\n",
        "                 act_layer = nn.GELU,\n",
        "                 norm_layer = nn.LayerNorm,\n",
        "                 sr_ratio = 7.,\n",
        "                 kernel_size = 3,\n",
        "                 with_bn = True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.leatt = LocallyEnhancedAttention(dim, num_heads, qkv_bias = qkv_bias, attn_drop = attn_drop,\n",
        "                                              proj_drop = drop, kernel_size = kernel_size, sr_ratio = sr_ratio)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0 else nn.Identity()\n",
        "\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        self.leff = LocallyEnhancedFeedForward(in_features = dim, hidden_features = dim * mlp_ratio,\n",
        "                                               act_layer = act_layer, drop = drop, \n",
        "                                               kernel_size = kernel_size, with_bn = with_bn)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path(self.leatt(self.norm1(x)))\n",
        "        x = x + self.drop_path(self.leff(self.norm2(x)))\n",
        "        return x"
      ],
      "metadata": {
        "id": "3CUVdoUjarqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LocallyEnhancedConvTransformer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 img_size = 224, \n",
        "                 patch_size = 7,\n",
        "                 in_chans = 3,\n",
        "                 kernel_size = 3,\n",
        "                 num_classes = 100,\n",
        "                 embed_dims = [64, 128, 192],\n",
        "                 num_heads = [2, 4, 6],\n",
        "                 mlp_ratios = [2, 3, 4],\n",
        "                 qkv_bias = False,\n",
        "                 drop_rate = 0.1,\n",
        "                 attn_drop_rate = 0.,\n",
        "                 drop_path_rate = 0.1,\n",
        "                 depths = [1, 3, 1],\n",
        "                 num_stages = 3,\n",
        "                 act_layer = nn.GELU,\n",
        "                 norm_layer = partial(nn.LayerNorm, eps = 1e-6),\n",
        "                 with_bn = True):\n",
        "        \"\"\"\n",
        "        args:\n",
        "            - img_size (:obj:'int') : input image size\n",
        "            - patch_size (:obj:'int') : patch size\n",
        "            - in_chans (:obj:'int') : input channels\n",
        "            - kernel_size (:obj:'int') : kernel size for conv in attention module\n",
        "            - num_classes (:obj:''int) : number of classes\n",
        "            - embed_dims (:obj:`list`): list of embeddings dimensions for tokens\n",
        "            - num_heads (:obj:`list`): list of numbers of heads in multi-head self-attention\n",
        "            - mlp_ratio (:obj:`list`): expand ratio in feedforward\n",
        "            - qkv_bias (:obj:`bool`): whether to add bias for mlp of qkv\n",
        "            - drop_rate (:obj:`float`): dropout rate in feedforward module after linear operation\n",
        "                and projection drop rate in attention\n",
        "            - attn_drop_rate (:obj:`float`): dropout rate for attention\n",
        "            - drop_path_rate (:obj:`float`): drop_path rate after attention\n",
        "            - depths (:obj: 'list') : list of depth for each stage\n",
        "            - num_stages (:obj:'int') : number of stage\n",
        "            - act_layer (:obj:'nn.Module') : activation function type\n",
        "            - norm_layer (:obj:`nn.Module`): normalization type\n",
        "            - with_bn (:obj:'bool') : whether add bn in LocallyEnhancedFeedForward\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.depths = depths\n",
        "        self.num_stages = num_stages\n",
        "\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]   # Stochastic depth decay rule\n",
        "        cur = 0\n",
        "\n",
        "        for i in range(num_stages):\n",
        "            patch_embed = ConvEmbedding(patch_size = patch_size if i == 0 else 3,\n",
        "                                        stride = 4 if i == 0 else 2,\n",
        "                                        in_chans = 3 if i == 0 else embed_dims[i - 1],\n",
        "                                        embed_dim = embed_dims[i])\n",
        "            blocks = nn.ModuleList([\n",
        "                                    Block(embed_dims[i], num_heads = num_heads[i],\n",
        "                                          mlp_ratio = mlp_ratios[i], qkv_bias = qkv_bias,\n",
        "                                          drop = drop_rate, attn_drop = attn_drop_rate,\n",
        "                                          drop_path = dpr[cur + j], act_layer = act_layer,\n",
        "                                          norm_layer = norm_layer, sr_ratio = 14 if i == 0 else 7,\n",
        "                                          kernel_size = kernel_size, with_bn = with_bn) for j in range(depths[i])\n",
        "            ])\n",
        "            norm = norm_layer(embed_dims[i])\n",
        "            cur += depths[i]\n",
        "\n",
        "            setattr(self, f\"patch_embed{i + 1}\", patch_embed)\n",
        "            setattr(self, f\"blocks{i + 1}\", blocks)\n",
        "            setattr(self, f\"norm{i + 1}\", norm)\n",
        "        \n",
        "        # Classifier Head\n",
        "        self.head = nn.Linear(embed_dims[-1], num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std = .02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0.)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "    \n",
        "    def get_classifier(self):\n",
        "        return self.head\n",
        "    \n",
        "    def reset_classifier(self, num_classes, global_pool = ''):\n",
        "        self.num_classes = num_classes\n",
        "        self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0. else nn.Identity()\n",
        "    \n",
        "    def forward_features(self, x):\n",
        "        B = x.shape[0]\n",
        "\n",
        "        for i in range(self.num_stages):\n",
        "            patch_embed = getattr(self, f\"patch_embed{i + 1}\")\n",
        "            blocks = getattr(self, f\"blocks{i + 1}\")\n",
        "            norm = getattr(self, f\"norm{i + 1}\")\n",
        "\n",
        "            x, H, W = patch_embed(x)\n",
        "            for block in blocks:\n",
        "                x = block(x)\n",
        "            x = norm(x)\n",
        "\n",
        "            if i != self.num_stages - 1:\n",
        "                x = x.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "        return x.mean(dim = 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.forward_features(x)\n",
        "        x = self.head(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "kzQrDMKBeMHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LocallyEnhancedConvTransformer(num_classes = 10).to(device)\n",
        "\n",
        "\n",
        "loss_history = {'train' : [], 'val' : []}\n",
        "acc_history = {'train' : [], 'val' : []}"
      ],
      "metadata": {
        "id": "60On1ncLr2D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return params / 1000000"
      ],
      "metadata": {
        "id": "Hj_ROqpYsakl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(count_parameters(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQaefjhdstiN",
        "outputId": "95423bbe-6695-48b2-a418-d8f3d98e8bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.151562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "-0vXJi_q3gh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습하기"
      ],
      "metadata": {
        "id": "jgKe99FDu3Kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001, weight_decay = 0.05)\n",
        "\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "lr_scheduler = CosineAnnealingLR(optimizer,T_max = 60)"
      ],
      "metadata": {
        "id": "tv2z8iE8swIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "def loss_acc_batch(output, target, max_norm = 5, train = True):\n",
        "    loss_batch = criterion(output, target)\n",
        "    _, predicted = torch.max(output, dim = -1)\n",
        "    correct_batch = (predicted == target).sum().item()\n",
        "\n",
        "    # Train the model\n",
        "    if train:\n",
        "        optimizer.zero_grad()\n",
        "        loss_batch.backward()\n",
        "        if max_norm is not None:\n",
        "            nn.utils.clip_grad_norm(model.parameters(), max_norm)\n",
        "        optimizer.step()\n",
        "\n",
        "    return loss_batch.item(), correct_batch"
      ],
      "metadata": {
        "id": "bv0hztqHu5zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_train = {\n",
        "    'num_epochs':60,\n",
        "    'max_norm': 5,\n",
        "    'optimizer':optimizer,\n",
        "    'criterion': criterion,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'filename': 'CIFAR10_LeCTv2_60_epochs.pth.tar',\n",
        "}"
      ],
      "metadata": {
        "id": "3FNm4Rsqu9hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(model, params):\n",
        "    num_epochs = params['num_epochs']\n",
        "    max_norm = params['max_norm']\n",
        "    criterion = params['criterion']\n",
        "    optimizer = params['optimizer']\n",
        "    sanity_check = params['sanity_check']\n",
        "    lr_scheduler = params['lr_scheduler']\n",
        "    filename = params['filename']\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_model_checkpoint = copy.deepcopy(model.state_dict())\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        curr_lr = get_lr(optimizer)\n",
        "        print(\"Epoch {} / {}, current lr = {}\".format(epoch + 1, num_epochs, curr_lr))\n",
        "\n",
        "        model.train()\n",
        "\n",
        "\n",
        "        train_loss = 0.\n",
        "        train_correct = 0.\n",
        "        total = len(train_dataset)\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            loss_batch, correct_batch = loss_acc_batch(outputs, labels, max_norm)\n",
        "\n",
        "            train_loss += loss_batch\n",
        "            train_correct += correct_batch\n",
        "\n",
        "            if sanity_check is True:\n",
        "                break\n",
        "        lr_scheduler.step()\n",
        "        \n",
        "        train_loss = train_loss / total\n",
        "        train_acc = train_correct / total\n",
        "\n",
        "        loss_history['train'].append(train_loss)\n",
        "        acc_history['train'].append(train_acc)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0\n",
        "            val_correct = 0\n",
        "            total = len(valid_dataset)\n",
        "\n",
        "            for imgs, labels in valid_loader:\n",
        "                imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(imgs)\n",
        "                loss_batch, correct_batch = loss_acc_batch(outputs, labels, train = False)\n",
        "\n",
        "                val_loss += loss_batch\n",
        "                val_correct += correct_batch\n",
        "\n",
        "                if sanity_check is True:\n",
        "                    break\n",
        "            \n",
        "            val_loss = val_loss / total\n",
        "            val_acc = val_correct / total\n",
        "\n",
        "        loss_history['val'].append(val_loss)\n",
        "        acc_history['val'].append(val_acc)\n",
        "        \n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_checkpoint = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), filename)\n",
        "            print(\"copied best model weights!\")\n",
        "        \n",
        "        \n",
        "        print('train loss : %.6f, val loss : %.6f, accuracy : %.2f, time %.4f min' %\n",
        "              (train_loss, val_loss, 100 * val_acc, (time.time() - start_time) / 60))\n",
        "        print(\"-\" * 10)\n",
        "    \n",
        "    model.load_state_dict(best_model_checkpoint)\n",
        "    return model, loss_history, acc_history"
      ],
      "metadata": {
        "id": "W176XvwEvA5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, loss_history, acc_history = train_fn(model, params_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5_jlSECvFKK",
        "outputId": "6df5fc74-4322-4247-bce2-cb20d717debd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 60, current lr = 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copied best model weights!\n",
            "train loss : 0.024921, val loss : 0.017696, accuracy : 59.35, time 10.7264 min\n",
            "----------\n",
            "Epoch 2 / 60, current lr = 0.0009993147673772868\n",
            "copied best model weights!\n",
            "train loss : 0.017599, val loss : 0.014217, accuracy : 67.95, time 21.4337 min\n",
            "----------\n",
            "Epoch 3 / 60, current lr = 0.0009972609476841365\n",
            "copied best model weights!\n",
            "train loss : 0.014778, val loss : 0.013583, accuracy : 69.73, time 32.1083 min\n",
            "----------\n",
            "Epoch 4 / 60, current lr = 0.0009938441702975688\n",
            "copied best model weights!\n",
            "train loss : 0.013086, val loss : 0.011723, accuracy : 73.98, time 42.7716 min\n",
            "----------\n",
            "Epoch 5 / 60, current lr = 0.0009890738003669028\n",
            "copied best model weights!\n",
            "train loss : 0.011794, val loss : 0.009429, accuracy : 79.20, time 53.4441 min\n",
            "----------\n",
            "Epoch 6 / 60, current lr = 0.0009829629131445341\n",
            "train loss : 0.010737, val loss : 0.009746, accuracy : 79.01, time 64.1089 min\n",
            "----------\n",
            "Epoch 7 / 60, current lr = 0.0009755282581475769\n",
            "copied best model weights!\n",
            "train loss : 0.009978, val loss : 0.008693, accuracy : 80.98, time 74.8091 min\n",
            "----------\n",
            "Epoch 8 / 60, current lr = 0.0009667902132486009\n",
            "copied best model weights!\n",
            "train loss : 0.009429, val loss : 0.007836, accuracy : 83.29, time 85.5222 min\n",
            "----------\n",
            "Epoch 9 / 60, current lr = 0.0009567727288213005\n",
            "copied best model weights!\n",
            "train loss : 0.009067, val loss : 0.007494, accuracy : 83.58, time 96.2577 min\n",
            "----------\n",
            "Epoch 10 / 60, current lr = 0.0009455032620941839\n",
            "copied best model weights!\n",
            "train loss : 0.008572, val loss : 0.006296, accuracy : 86.54, time 106.9826 min\n",
            "----------\n",
            "Epoch 11 / 60, current lr = 0.0009330127018922195\n",
            "train loss : 0.008214, val loss : 0.007370, accuracy : 84.13, time 117.7325 min\n",
            "----------\n",
            "Epoch 12 / 60, current lr = 0.0009193352839727121\n",
            "copied best model weights!\n",
            "train loss : 0.007879, val loss : 0.005962, accuracy : 87.05, time 128.4423 min\n",
            "----------\n",
            "Epoch 13 / 60, current lr = 0.0009045084971874737\n",
            "copied best model weights!\n",
            "train loss : 0.007568, val loss : 0.005956, accuracy : 86.84, time 139.1609 min\n",
            "----------\n",
            "Epoch 14 / 60, current lr = 0.0008885729807284855\n",
            "train loss : 0.007349, val loss : 0.006064, accuracy : 87.10, time 149.8807 min\n",
            "----------\n",
            "Epoch 15 / 60, current lr = 0.0008715724127386972\n",
            "copied best model weights!\n",
            "train loss : 0.007101, val loss : 0.005682, accuracy : 87.70, time 160.6186 min\n",
            "----------\n",
            "Epoch 16 / 60, current lr = 0.0008535533905932738\n",
            "train loss : 0.006915, val loss : 0.005859, accuracy : 87.35, time 171.3676 min\n",
            "----------\n",
            "Epoch 17 / 60, current lr = 0.0008345653031794292\n",
            "train loss : 0.006677, val loss : 0.005773, accuracy : 87.96, time 182.1053 min\n",
            "----------\n",
            "Epoch 18 / 60, current lr = 0.0008146601955249188\n",
            "copied best model weights!\n",
            "train loss : 0.006498, val loss : 0.004923, accuracy : 89.42, time 192.8623 min\n",
            "----------\n",
            "Epoch 19 / 60, current lr = 0.0007938926261462366\n",
            "train loss : 0.006294, val loss : 0.004949, accuracy : 89.18, time 203.6116 min\n",
            "----------\n",
            "Epoch 20 / 60, current lr = 0.0007723195175075136\n",
            "copied best model weights!\n",
            "train loss : 0.006126, val loss : 0.004585, accuracy : 89.98, time 214.3606 min\n",
            "----------\n",
            "Epoch 21 / 60, current lr = 0.00075\n",
            "train loss : 0.005974, val loss : 0.004950, accuracy : 89.34, time 225.0940 min\n",
            "----------\n",
            "Epoch 22 / 60, current lr = 0.0007269952498697733\n",
            "copied best model weights!\n",
            "train loss : 0.005769, val loss : 0.004494, accuracy : 90.38, time 235.8646 min\n",
            "----------\n",
            "Epoch 23 / 60, current lr = 0.0007033683215379002\n",
            "train loss : 0.005602, val loss : 0.004578, accuracy : 90.23, time 246.6257 min\n",
            "----------\n",
            "Epoch 24 / 60, current lr = 0.0006791839747726503\n",
            "train loss : 0.005465, val loss : 0.004699, accuracy : 89.96, time 257.3891 min\n",
            "----------\n",
            "Epoch 25 / 60, current lr = 0.0006545084971874737\n",
            "copied best model weights!\n",
            "train loss : 0.005261, val loss : 0.004416, accuracy : 90.86, time 268.1550 min\n",
            "----------\n",
            "Epoch 26 / 60, current lr = 0.0006294095225512603\n",
            "copied best model weights!\n",
            "train loss : 0.005112, val loss : 0.004234, accuracy : 91.26, time 278.9568 min\n",
            "----------\n",
            "Epoch 27 / 60, current lr = 0.0006039558454088795\n",
            "copied best model weights!\n",
            "train loss : 0.004961, val loss : 0.004005, accuracy : 91.41, time 289.7573 min\n",
            "----------\n",
            "Epoch 28 / 60, current lr = 0.0005782172325201154\n",
            "train loss : 0.004834, val loss : 0.004021, accuracy : 91.28, time 300.5548 min\n",
            "----------\n",
            "Epoch 29 / 60, current lr = 0.0005522642316338267\n",
            "train loss : 0.004741, val loss : 0.004052, accuracy : 91.20, time 311.3476 min\n",
            "----------\n",
            "Epoch 30 / 60, current lr = 0.0005261679781214719\n",
            "copied best model weights!\n",
            "train loss : 0.004663, val loss : 0.003897, accuracy : 91.53, time 322.1158 min\n",
            "----------\n",
            "Epoch 31 / 60, current lr = 0.0005000000000000001\n",
            "train loss : 0.004425, val loss : 0.003930, accuracy : 91.84, time 332.8939 min\n",
            "----------\n",
            "Epoch 32 / 60, current lr = 0.00047383202187852816\n",
            "train loss : 0.004281, val loss : 0.004052, accuracy : 91.94, time 343.6747 min\n",
            "----------\n",
            "Epoch 33 / 60, current lr = 0.00044773576836617336\n",
            "copied best model weights!\n",
            "train loss : 0.004227, val loss : 0.003642, accuracy : 92.12, time 354.4673 min\n",
            "----------\n",
            "Epoch 34 / 60, current lr = 0.0004217827674798846\n",
            "copied best model weights!\n",
            "train loss : 0.004007, val loss : 0.003633, accuracy : 92.08, time 365.2432 min\n",
            "----------\n",
            "Epoch 35 / 60, current lr = 0.00039604415459112036\n",
            "copied best model weights!\n",
            "train loss : 0.003924, val loss : 0.003553, accuracy : 92.60, time 376.0440 min\n",
            "----------\n",
            "Epoch 36 / 60, current lr = 0.00037059047744873974\n",
            "train loss : 0.003784, val loss : 0.003672, accuracy : 92.41, time 386.8442 min\n",
            "----------\n",
            "Epoch 37 / 60, current lr = 0.0003454915028125264\n",
            "copied best model weights!\n",
            "train loss : 0.003640, val loss : 0.003386, accuracy : 92.98, time 397.6573 min\n",
            "----------\n",
            "Epoch 38 / 60, current lr = 0.0003208160252273499\n",
            "train loss : 0.003583, val loss : 0.003546, accuracy : 92.96, time 408.4344 min\n",
            "----------\n",
            "Epoch 39 / 60, current lr = 0.00029663167846210003\n",
            "copied best model weights!\n",
            "train loss : 0.003429, val loss : 0.003299, accuracy : 93.26, time 419.2620 min\n",
            "----------\n",
            "Epoch 40 / 60, current lr = 0.0002730047501302267\n",
            "train loss : 0.003278, val loss : 0.003367, accuracy : 93.03, time 430.0820 min\n",
            "----------\n",
            "Epoch 41 / 60, current lr = 0.00025000000000000017\n",
            "train loss : 0.003238, val loss : 0.003350, accuracy : 93.13, time 440.9087 min\n",
            "----------\n",
            "Epoch 42 / 60, current lr = 0.00022768048249248665\n",
            "train loss : 0.003149, val loss : 0.003488, accuracy : 93.24, time 451.7204 min\n",
            "----------\n",
            "Epoch 43 / 60, current lr = 0.00020610737385376354\n",
            "train loss : 0.002972, val loss : 0.003490, accuracy : 93.23, time 462.5288 min\n",
            "----------\n",
            "Epoch 44 / 60, current lr = 0.0001853398044750814\n",
            "train loss : 0.002818, val loss : 0.003383, accuracy : 93.14, time 473.3280 min\n",
            "----------\n",
            "Epoch 45 / 60, current lr = 0.0001654346968205711\n",
            "copied best model weights!\n",
            "train loss : 0.002747, val loss : 0.003228, accuracy : 93.51, time 484.1344 min\n",
            "----------\n",
            "Epoch 46 / 60, current lr = 0.0001464466094067263\n",
            "train loss : 0.002673, val loss : 0.003291, accuracy : 93.24, time 494.9318 min\n",
            "----------\n",
            "Epoch 47 / 60, current lr = 0.00012842758726130303\n",
            "copied best model weights!\n",
            "train loss : 0.002572, val loss : 0.003194, accuracy : 93.71, time 505.7522 min\n",
            "----------\n",
            "Epoch 48 / 60, current lr = 0.00011142701927151459\n",
            "copied best model weights!\n",
            "train loss : 0.002521, val loss : 0.003081, accuracy : 93.94, time 516.5816 min\n",
            "----------\n",
            "Epoch 49 / 60, current lr = 9.549150281252635e-05\n",
            "train loss : 0.002482, val loss : 0.003184, accuracy : 93.65, time 527.3164 min\n",
            "----------\n",
            "Epoch 50 / 60, current lr = 8.066471602728805e-05\n",
            "copied best model weights!\n",
            "train loss : 0.002403, val loss : 0.003021, accuracy : 94.03, time 538.0533 min\n",
            "----------\n",
            "Epoch 51 / 60, current lr = 6.698729810778066e-05\n",
            "train loss : 0.002270, val loss : 0.003065, accuracy : 94.02, time 548.7692 min\n",
            "----------\n",
            "Epoch 52 / 60, current lr = 5.449673790581612e-05\n",
            "train loss : 0.002241, val loss : 0.003046, accuracy : 94.05, time 559.5094 min\n",
            "----------\n",
            "Epoch 53 / 60, current lr = 4.322727117869952e-05\n",
            "train loss : 0.002157, val loss : 0.003033, accuracy : 94.30, time 570.2358 min\n",
            "----------\n",
            "Epoch 54 / 60, current lr = 3.3209786751399136e-05\n",
            "train loss : 0.002187, val loss : 0.003032, accuracy : 94.31, time 580.9698 min\n",
            "----------\n",
            "Epoch 55 / 60, current lr = 2.4471741852423238e-05\n",
            "train loss : 0.002100, val loss : 0.003025, accuracy : 94.21, time 591.6756 min\n",
            "----------\n",
            "Epoch 56 / 60, current lr = 1.7037086855465846e-05\n",
            "copied best model weights!\n",
            "train loss : 0.002100, val loss : 0.002982, accuracy : 94.31, time 602.3753 min\n",
            "----------\n",
            "Epoch 57 / 60, current lr = 1.0926199633097158e-05\n",
            "copied best model weights!\n",
            "train loss : 0.002064, val loss : 0.002974, accuracy : 94.22, time 613.0875 min\n",
            "----------\n",
            "Epoch 58 / 60, current lr = 6.155829702431172e-06\n",
            "copied best model weights!\n",
            "train loss : 0.002057, val loss : 0.002972, accuracy : 94.30, time 623.8285 min\n",
            "----------\n",
            "Epoch 59 / 60, current lr = 2.7390523158633003e-06\n",
            "copied best model weights!\n",
            "train loss : 0.002023, val loss : 0.002958, accuracy : 94.31, time 634.5556 min\n",
            "----------\n",
            "Epoch 60 / 60, current lr = 6.852326227130837e-07\n",
            "train loss : 0.001981, val loss : 0.003023, accuracy : 94.21, time 645.2953 min\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "num_epochs = params_train['num_epochs']\n",
        "\n",
        "# Plot train-val loss\n",
        "plt.title('Train-Val Loss')\n",
        "plt.plot(range(1, num_epochs + 1), loss_history['train'], label = 'train')\n",
        "plt.plot(range(1, num_epochs + 1), loss_history['val'], label = 'val')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Training Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot train-val accuracy\n",
        "plt.title('Train-Val Accuracy')\n",
        "plt.plot(range(1, num_epochs + 1), acc_history['train'], label = 'train')\n",
        "plt.plot(range(1, num_epochs + 1), acc_history['val'], label = 'val')\n",
        "plt.xlabel('Training epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "EwkkxLZivM84",
        "outputId": "986b7156-f6f1-47a5-bb72-6f32425dbb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('CIFAR10_LeCTv2_loss_history_2.json', 'w') as f:\n",
        "    json.dump(loss_history, f, indent = 4)\n",
        "\n",
        "with open('CIFAR10_LeCTv2_acc_history_2.json', 'w') as g:\n",
        "    json.dump(acc_history, g, indent = 4)"
      ],
      "metadata": {
        "id": "iONfxv1avVHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L-dvbaD6zWKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
